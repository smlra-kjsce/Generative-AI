{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM6RTNbUCrc2TID52+V0KX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smlra-kjsce/Generative-AI/blob/main/RNNs_and_LSTMs/Vanilla_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimal character-level Vanilla RNN model"
      ],
      "metadata": {
        "id": "6tcZRWtQBbC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_bk4RlqzBWXV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def zero_init(a,b):\n",
        "    return np.zeros((a,b))\n",
        "\n",
        "# To read the training data and make a vocabulary and dictiornary to index the chars\n",
        "class DataReader:\n",
        "    def __init__(self, path, seq_length):\n",
        "        #uncomment below , if you dont want to use any file for text reading and comment next 2 lines\n",
        "        self.data = \"some really long text to test this. maybe not perfect but should get you going.\"\n",
        "        # self.fp = open(path, \"r\")\n",
        "        # self.data = self.fp.read()\n",
        "        #find unique chars\n",
        "        chars = list(set(self.data))\n",
        "        #create dictionary mapping for each char\n",
        "        self.char_to_ix = {ch:i for (i,ch) in enumerate(chars)}\n",
        "        self.ix_to_char = {i:ch for (i,ch) in enumerate(chars)}\n",
        "        #total data\n",
        "        self.data_size = len(self.data)\n",
        "        #num of unique chars\n",
        "        self.vocab_size = len(chars)\n",
        "        self.pointer = 0\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def next_batch(self):\n",
        "        input_start = self.pointer\n",
        "        input_end = self.pointer + self.seq_length\n",
        "        inputs = [self.char_to_ix[ch] for ch in self.data[input_start:input_end]]\n",
        "        targets = [self.char_to_ix[ch] for ch in self.data[input_start+1:input_end+1]]\n",
        "        self.pointer += self.seq_length\n",
        "        if self.pointer + self.seq_length + 1 >= self.data_size:\n",
        "            # reset pointer\n",
        "            self.pointer = 0\n",
        "        return inputs, targets\n",
        "\n",
        "    def just_started(self):\n",
        "        return self.pointer == 0\n",
        "\n",
        "    def close(self):\n",
        "        self.fp.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN:\n",
        "    def __init__(self, hidden_size, vocab_size, seq_length, learning_rate):\n",
        "        # hyper parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_length = seq_length\n",
        "        self.learning_rate = learning_rate\n",
        "        # model parameters\n",
        "        self.U = np.random.uniform(-np.sqrt(1./vocab_size), np.sqrt(1./vocab_size), (hidden_size, vocab_size))\n",
        "        self.V = np.random.uniform(-np.sqrt(1./hidden_size), np.sqrt(1./hidden_size), (vocab_size, hidden_size))\n",
        "        self.W = np.random.uniform(-np.sqrt(1./hidden_size), np.sqrt(1./hidden_size), (hidden_size, hidden_size))\n",
        "        self.b = np.zeros((hidden_size, 1)) # bias for hidden layer\n",
        "        self.c = np.zeros((vocab_size, 1)) # bias for output\n",
        "        \n",
        "        # memory vars for adagrad, \n",
        "        #ignore if you implement another approach\n",
        "        self.mU = np.zeros_like(self.U)\n",
        "        self.mW = np.zeros_like(self.W)\n",
        "        self.mV = np.zeros_like(self.V)\n",
        "        self.mb = np.zeros_like(self.b)\n",
        "        self.mc = np.zeros_like(self.c)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        p = np.exp(x- np.max(x))\n",
        "        return p / np.sum(p)\n",
        "        \n",
        "    def forward(self, inputs, hprev):\n",
        "            xs, hs, os, ycap = {}, {}, {}, {}\n",
        "            hs[-1] = np.copy(hprev)\n",
        "            for t in range(len(inputs)):\n",
        "                xs[t] = zero_init(self.vocab_size,1)\n",
        "                xs[t][inputs[t]] = 1 # one hot encoding , 1-of-k\n",
        "                hs[t] = np.tanh(np.dot(self.U,xs[t]) + np.dot(self.W,hs[t-1]) + self.b) # hidden state\n",
        "                os[t] = np.dot(self.V,hs[t]) + self.c # unnormalised log probs for next char\n",
        "                ycap[t] = self.softmax(os[t]) # probs for next char\n",
        "            return xs, hs, ycap\n",
        "        \n",
        "    def backward(self, xs, hs, ps, targets):\n",
        "            # backward pass: compute gradients going backwards\n",
        "            dU, dW, dV = np.zeros_like(self.U), np.zeros_like(self.W), np.zeros_like(self.V)\n",
        "            db, dc = np.zeros_like(self.b), np.zeros_like(self.c)\n",
        "            dhnext = np.zeros_like(hs[0])\n",
        "            for t in reversed(range(self.seq_length)):\n",
        "                dy = np.copy(ps[t])\n",
        "                #through softmax\n",
        "                dy[targets[t]] -= 1 # backprop into y\n",
        "                #calculate dV, dc\n",
        "                dV += np.dot(dy, hs[t].T)\n",
        "                dc += dc\n",
        "                #dh includes gradient from two sides, next cell and current output\n",
        "                dh = np.dot(self.V.T, dy) + dhnext # backprop into h\n",
        "                # backprop through tanh non-linearity \n",
        "                dhrec = (1 - hs[t] * hs[t]) * dh  #dhrec is the term used in many equations\n",
        "                db += dhrec\n",
        "                #calculate dU and dW\n",
        "                dU += np.dot(dhrec, xs[t].T)\n",
        "                dW += np.dot(dhrec, hs[t-1].T)\n",
        "                #pass the gradient from next cell to the next iteration.\n",
        "                dhnext = np.dot(self.W.T, dhrec)\n",
        "            # clip to mitigate exploding gradients\n",
        "            for dparam in [dU, dW, dV, db, dc]:\n",
        "                np.clip(dparam, -5, 5, out=dparam) \n",
        "            return dU, dW, dV, db, dc\n",
        "    \n",
        "    def loss(self, ps, targets):\n",
        "            \"\"\"loss for a sequence\"\"\"\n",
        "            # calculate cross-entrpy loss\n",
        "            return sum(-np.log(ps[t][targets[t],0]) for t in range(self.seq_length))\n",
        "        \n",
        "    \n",
        "    def update_model(self, dU, dW, dV, db, dc):\n",
        "        # parameter update with adagrad\n",
        "        for param, dparam, mem in zip([self.U, self.W, self.V, self.b, self.c],\n",
        "                                  [dU, dW, dV, db, dc],\n",
        "                                  [self.mU, self.mW, self.mV, self.mb, self.mc]):\n",
        "            mem += dparam*dparam\n",
        "            param += -self.learning_rate*dparam/np.sqrt(mem+1e-8) # adagrad update\n",
        "                \n",
        "                \n",
        "    def sample(self, h, seed_ix, n):\n",
        "            \"\"\"\n",
        "            sample a sequence of integers from the model\n",
        "            h is memory state, seed_ix is seed letter from the first time step\n",
        "            \"\"\"\n",
        "            x = zero_init(self.vocab_size, 1)\n",
        "            x[seed_ix] = 1\n",
        "            ixes = []\n",
        "            for t in range(n):\n",
        "                h = np.tanh(np.dot(self.U, x) + np.dot(self.W, h) + self.b)\n",
        "                y = np.dot(self.V, h) + self.c\n",
        "                p = np.exp(y)/np.sum(np.exp(y))\n",
        "                ix = np.random.choice(range(self.vocab_size), p = p.ravel())\n",
        "                x = zero_init(self.vocab_size,1)\n",
        "                x[ix] = 1\n",
        "                ixes.append(ix)\n",
        "            return ixes\n",
        "\n",
        "    def train(self, data_reader):\n",
        "            iter_num = 0\n",
        "            threshold = 0.01\n",
        "            smooth_loss = -np.log(1.0/data_reader.vocab_size)*self.seq_length\n",
        "            while (smooth_loss > threshold):\n",
        "                if data_reader.just_started():\n",
        "                    hprev = np.zeros((self.hidden_size,1))\n",
        "                inputs, targets = data_reader.next_batch()\n",
        "                xs, hs, ps = self.forward(inputs, hprev)\n",
        "                dU, dW, dV, db, dc = self.backward(xs, hs, ps, targets)\n",
        "                loss = self.loss(ps, targets)\n",
        "                self.update_model(dU, dW, dV, db, dc)\n",
        "                smooth_loss = smooth_loss*0.999 + loss*0.001\n",
        "                hprev = hs[self.seq_length-1]\n",
        "                if not iter_num%500:\n",
        "                    sample_ix = self.sample(hprev, inputs[0], 200)\n",
        "                    print( ''.join(data_reader.ix_to_char[ix] for ix in sample_ix))\n",
        "                    print( \"\\n\\niter :%d, loss:%f\"%(iter_num, smooth_loss))\n",
        "                iter_num += 1\n",
        "\n",
        "    def predict(self, data_reader, start, n):\n",
        "\n",
        "        #initialize input vector\n",
        "        x = zero_init(self.vocab_size, 1)\n",
        "        chars = [ch for ch in start]\n",
        "        ixes = []\n",
        "        for i in range(len(chars)):\n",
        "            ix = data_reader.char_to_ix[chars[i]]\n",
        "            x[ix] = 1\n",
        "            ixes.append(ix)\n",
        "\n",
        "        h = np.zeros((self.hidden_size,1))\n",
        "        # predict next n chars\n",
        "        for t in range(n):\n",
        "            h = np.tanh(np.dot(self.U, x) + np.dot(self.W, h) + self.b)\n",
        "            y = np.dot(self.V, h) + self.c\n",
        "            p = np.exp(y)/np.sum(np.exp(y))\n",
        "            ix = np.random.choice(range(self.vocab_size), p = p.ravel())\n",
        "            x = zero_init(self.vocab_size,1)\n",
        "            x[ix] = 1\n",
        "            ixes.append(ix)\n",
        "        txt = ''.join(data_reader.ix_to_char[i] for i in ixes)\n",
        "        return txt"
      ],
      "metadata": {
        "id": "hpFSoOqTB0mJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 25\n",
        "#read text from the \"input.txt\" file\n",
        "data_reader = DataReader(\"input.txt\", seq_length)\n",
        "rnn = RNN(hidden_size=100, vocab_size=data_reader.vocab_size,seq_length=seq_length,learning_rate=1e-1)\n",
        "rnn.train(data_reader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-UqZko6CBeb",
        "outputId": "c498ebc5-efb4-4412-b79b-eb2d156fce86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ublftg hex.rebfxto t onbpn.p.rdcgulo ponxtsfhtmcpdsnxxrg yo.aurbpyd.y ofcxamfxmncnx iofg.mxll.it t.ambiextxhde trggeanlfusnh.lyoinhpidlxydoorco.xgonxho cxx oaacygumxofncooocs a.l.tf. lemr.rpeyb nu.opm\n",
            "\n",
            "\n",
            "iter :0, loss:77.277327\n",
            "t you ferfect you should get you goit you goit this. maybe notext to test maybe not goiylmy long teald get tou hoiuld get but sget youg text peruget but should get youngoi. yon goia longotext to to te\n",
            "\n",
            "\n",
            "iter :500, loss:56.850618\n",
            " test tuug text xo test this. maybe not perfect but hhould get you goit cong text to test you goifld get you perfect but should get yousgoiald get you go t you goit you goitld get you goit you goit yo\n",
            "\n",
            "\n",
            "iter :1000, loss:34.956112\n",
            "o test this. maybe not perfect not perfect but should get you goit you goitt should get you goially long text to test maybe not perfect but should get you goia long text to test this. maybe not perfec\n",
            "\n",
            "\n",
            "iter :1500, loss:21.372727\n",
            "t you goit you goit you goially long text to test this. maybe not perfect but should get you goit you goially long text to test this. maybe not perfect but should get you goially long get you goia lon\n",
            "\n",
            "\n",
            "iter :2000, loss:13.066005\n",
            "ct but should get you goiallo long text to test this. maybe not perfect but should get you goit you goially long text to test this. maybe not perfect but should get you goially long text to test this.\n",
            "\n",
            "\n",
            "iter :2500, loss:7.997439\n",
            "est this. maybe not perfect but should get you goiallong text to test thiso maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goially long text \n",
            "\n",
            "\n",
            "iter :3000, loss:4.906422\n",
            "t you goit you goit you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goiald ng text to test this. maybe not\n",
            "\n",
            "\n",
            "iter :3500, loss:3.021112\n",
            "ct but should get you goit you goially long text to test this. maybe not perfect but should get you goit you goiald get you goiallslly gbamsucs.ls.ms.msals.ls ls.lsally long text to tostest you goit y\n",
            "\n",
            "\n",
            "iter :4000, loss:1.870433\n",
            "est this. maybe not perfect but should get you goit you goio you goit you goit you goiallynlynlynlyomshlsais.is.msutet you goially long text to test this. maybe not perfect but should get you goiald t\n",
            "\n",
            "\n",
            "iter :4500, loss:1.167313\n",
            "t you goit you goit bet perfect but should get you goi. maybe not perfect but should get you goiy long text to test this. maybe not perfect but should get you goi. moybe not perfect but should get you\n",
            "\n",
            "\n",
            "iter :5000, loss:0.736930\n",
            "ctgbut should get you goit you goit you goit gotext to test this. maybe not perfect but should get you goit you goit  oest this. maybe not perfect but should get you goit d text to test this. maybe no\n",
            "\n",
            "\n",
            "iter :5500, loss:0.472742\n",
            "est this. maybe not perfect but should get you goit you goit you goit you goit you goit you goit gstext to test this. maybe not perfect but should get you goia you goially long text to test this. mayb\n",
            "\n",
            "\n",
            "iter :6000, loss:0.309955\n",
            "t you goit dong text to test this. maybe not perfect but shoully long text to test this. maybe not perfect but should get you goit you goit you goit not perfect but should get you goit you goit you go\n",
            "\n",
            "\n",
            "iter :6500, loss:0.209138\n",
            " test this. maybe not perfect but should get you goit mo not perfect but should get you goit you goiald ng text to test this. maybe not perfect but should get you goit nouthoit you goit you goiaybe no\n",
            "\n",
            "\n",
            "iter :7000, loss:0.146173\n",
            "est this. maybe not perfect but should get you goit not perfect but should get you goiald get you goit you goit you goit y t perfect but should gct but should get you goit you goit dshould get boy sho\n",
            "\n",
            "\n",
            "iter :7500, loss:0.106356\n",
            "t you goit you goit you goially long text to test this. maybe not perfect but should get you goit you goit you goit you goially long text to test this. maybe not perfect but should get you goit you go\n",
            "\n",
            "\n",
            "iter :8000, loss:0.080788\n",
            "ct but should get you goit you goit you goit sot perfect but should get you goiuld get you goit you goit bot perfect but should get you goially long text to test this. maybe not perfect but should get\n",
            "\n",
            "\n",
            "iter :8500, loss:0.064070\n",
            "est this. maybe not perfect but should get you goit you goit you goit you goit bouegest you goit you goit you goit you goia long text to test this. maybe not xt to test this. maybe not perfect but sho\n",
            "\n",
            "\n",
            "iter :9000, loss:0.052900\n",
            "t you goiald ge ng text to test this. maybe not perfect but should get you goia you goiallo long text to test this. maybe not perfect but should get you goit you goit you goiald get you goit notsperfe\n",
            "\n",
            "\n",
            "iter :9500, loss:0.045243\n",
            " test this. maybe not perfect but should get you goiuld get you goially long text to test this. maybe not perfect but should get you goit you goit gotext to test this. maybe not perfect but should get\n",
            "\n",
            "\n",
            "iter :10000, loss:0.039797\n",
            "est this. maybe not perfect but should get you goit you goit you goiald nlanlbng text to test this. maybe not perfect but should get you goiald teshout should get you goia long text to test this. mayb\n",
            "\n",
            "\n",
            "iter :10500, loss:0.035781\n",
            "a you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goit you goit mot perfect but should get you goiald get \n",
            "\n",
            "\n",
            "iter :11000, loss:0.032721\n",
            " test this. maybe not perfect but should get you goiald ng text to test this. maybe not perfect but should get you goit g text to test this. maybe not perfect but should get you goit bet perfect but s\n",
            "\n",
            "\n",
            "iter :11500, loss:0.030283\n",
            "eat but should get you goio d get yor goit you goit you goit you goiald ge ng text to test this. maybe not perfect but should get you goia maybe not perfect but should get you goit you goib gotext to \n",
            "\n",
            "\n",
            "iter :12000, loss:0.028279\n",
            "t you goit you goit you goiaybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goit you to to test this. maybe not perfect but should get you goial\n",
            "\n",
            "\n",
            "iter :12500, loss:0.026601\n",
            "ct but should get you goiald gly long text to test this. maybe not perfect but should get you goit you goit nou perfect but should get you goially long text to test this. maybe not perfect but should \n",
            "\n",
            "\n",
            "iter :13000, loss:0.025145\n",
            "eet this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goia you goia l\n",
            "\n",
            "\n",
            "iter :13500, loss:0.023863\n",
            "t you goiald get bou goit you goia you goit dotext to test this. maybe not perfect but should get you goit you goit bet perfect but should get you goit you goia long text to test this. maybe not perfe\n",
            "\n",
            "\n",
            "iter :14000, loss:0.022732\n",
            "ct but should get you goiuld get you goit you goiuld get you goiy yougeget you goit dhis. maybe not perfect but should get you goit you goially long text to test this. maybe not perfect but should get\n",
            "\n",
            "\n",
            "iter :14500, loss:0.021706\n",
            "est this. maybe not perfect but should get you goit sou goit you goiald ge teshould get you goit yot perfect but should get you goit you goit you goiou goiu maylyng text to test this. maybe not perfec\n",
            "\n",
            "\n",
            "iter :15000, loss:0.020772\n",
            "t you goially long text to test this. maybe not perfect but should get you goit not perfect but should get you goit you goialy ngutesnlynesomsarst this. maybe not perfect but should get you goiald nly\n",
            "\n",
            "\n",
            "iter :15500, loss:0.019927\n",
            "ct but should get you goiald tlong text to test this. maybe not perfect but should get you goit you goially long text to test this. maybe not perfect but should get you goit you goit you goit you goit\n",
            "\n",
            "\n",
            "iter :16000, loss:0.019143\n",
            "est this. maybe not perfect but should get you goit bou goit gotext to test this. maybe not perfect but should get you goit you goi. maybe not perfect but should get you goit you goially long text to \n",
            "\n",
            "\n",
            "iter :16500, loss:0.018416\n",
            "t you goially long text to test this. maybe not perfect but should get you goit you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfe\n",
            "\n",
            "\n",
            "iter :17000, loss:0.017751\n",
            "ct but should get you goit goteperfect but should get you goit you goit you goit gotext to test this. maybe not perfect but should get you goiy you goit you goit you goio long t xt to test this. maybe\n",
            "\n",
            "\n",
            "iter :17500, loss:0.017125\n",
            "est this. maybe not perfect but should get you goit you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goit y\n",
            "\n",
            "\n",
            "iter :18000, loss:0.016538\n",
            "a yougeget you goiald ge teshould get you goiuld get you goit nousperfect but should get you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe \n",
            "\n",
            "\n",
            "iter :18500, loss:0.015996\n",
            "ct but should get you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goi. maybe not perfect but should get yo\n",
            "\n",
            "\n",
            "iter :19000, loss:0.015481\n",
            "est this. maybe not perfect but should get you goit bet perfect but should get you goially long text to test this. maybe not perfect but should get you goiy you goiuld get you goiuld get you goiald ge\n",
            "\n",
            "\n",
            "iter :19500, loss:0.014995\n",
            "t you goit you goit you goiaybu bstext to test this. maybe not perfect but should get you goit you goiallo long text to test this. maybe not perfect but should get you goit you goit you goiy moug text\n",
            "\n",
            "\n",
            "iter :20000, loss:0.014544\n",
            " test this. maybe not perfect but should get you goiuld get you goit you goia long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should \n",
            "\n",
            "\n",
            "iter :20500, loss:0.014113\n",
            "est you goia bong text to test this. maybe not perfect but should get you goit nou perfect but should get you goit bet perfect but should get you goit you goit you goia you goially long text to test t\n",
            "\n",
            "\n",
            "iter :21000, loss:0.013704\n",
            "t you goit bet perfect but should get you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goially long text to\n",
            "\n",
            "\n",
            "iter :21500, loss:0.013324\n",
            "ct but should get you goio you goially long text to test this. maybe not perfect but should get sou goially long text to test this. maybe not perfect but should get you goio you goit you goiallong tep\n",
            "\n",
            "\n",
            "iter :22000, loss:0.012959\n",
            "ect but should get you goit you goiald gef gouefect but should get you goit you goially long text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect b\n",
            "\n",
            "\n",
            "iter :22500, loss:0.012612\n",
            "t you goially long text to test this. maybe not perfect but should get you goit you goiald ge tdsget you goit you goit you goiu moygeget you goiald ng text to test this. maybe not perfect but should g\n",
            "\n",
            "\n",
            "iter :23000, loss:0.012288\n",
            "ct but should get you goit you goiald nlong text to test this. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goit you goially long text to t\n",
            "\n",
            "\n",
            "iter :23500, loss:0.011976\n",
            "est this. maybe not perfect but should get you goit you goit you goially long text to test this. maybe not perfect but should get you goit you goially long text to test this. maybe not perfect but sho\n",
            "\n",
            "\n",
            "iter :24000, loss:0.011678\n",
            "a you goia long text to test this. maybe not perfect but should get you goiuld get you goially long text to test this. maybe not perfect but should get you goiaybu gstext to test this. maybe not perfe\n",
            "\n",
            "\n",
            "iter :24500, loss:0.011399\n",
            "ct but should get you goiuld get you goia you goit you goit nou perfect but should get you goit you goiy long text to test this. maybe not perfect but should get you goit you goially long text to test\n",
            "\n",
            "\n",
            "iter :25000, loss:0.011129\n",
            "est this. maybe not perfect but should get you goi. maybe not perfect but should get you goially long text to test this. maybe not perfect but should get you goiy you goially long text to test this. m\n",
            "\n",
            "\n",
            "iter :25500, loss:0.010871\n",
            "t you goit you goially long text to test this. maybe not perfect but should get you goit you goit you goially long text to test this. maybe not perfect but should get you goially long text to test thi\n",
            "\n",
            "\n",
            "iter :26000, loss:0.010628\n",
            "ct but should get you goiaylaybe not perfect but should get you goit you goit you goiu maybe not perfect but should get you goio you goit you goit you goiallong text to test this. maybe not perfect bu\n",
            "\n",
            "\n",
            "iter :26500, loss:0.010392\n",
            "est you goit nou perfect but should get you goiald ng text to test this. maybe not perfect but should get you goiu maybe not perfect but should get you goit you goially long text to test this. maybe n\n",
            "\n",
            "\n",
            "iter :27000, loss:0.010165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.predict(data_reader, 'get', 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YmbHOCYCCDVy",
        "outputId": "0443f5a8-59e7-4f7c-e660-4f86016a8e15"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get teeally long text to test this. maybe not perfect'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}